**Source:** https://arxiv.org/pdf/2506.08872

# Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task

## Authors
- Nataliya Kosmyna (MIT Media Lab, Cambridge, MA)
- Eugene Hauptmann (MIT, Cambridge, MA)
- Ye Tong Yuan (Wellesley College, Wellesley, MA)
- Jessica Situ (MIT, Cambridge, MA)
- Xian-Hao Liao (Mass. College of Art and Design, Boston, MA)
- Ashly Vivian Beresnitzky (MIT, Cambridge, MA)
- Iris Braunstein (MIT, Cambridge, MA)
- Pattie Maes (MIT Media Lab, Cambridge, MA)

Corresponding author: Nataliya Kosmyna (nkosmyna@mit.edu)

---

## Abstract

The widespread adoption of Large Language Models (LLMs) like ChatGPT has transformed educational and professional contexts. This study investigates the cognitive cost of LLM use in an essay writing task by assigning participants to three groups: LLM, Search Engine, and Brain-only. Over four sessions (with the fourth session involving a crossover of tool usage), the study analyzed essay content, brain activity (via EEG), and participant interviews. The findings indicate that LLM, Search Engine, and Brain-only groups develop distinct neural connectivity patterns, with cognitive engagement systematically decreasing as external support increases. The LLM group exhibited the weakest brain network coupling and lowest perceived essay ownership, while the Brain-only group demonstrated the most robust neural and behavioral indicators of cognitive engagement and learning. Over time, LLM use was associated with reduced learning skills and memory recall. The results highlight the need to understand the cognitive and practical impacts of AI on learning.

---

## Table of Contents
- Abstract
- Summary of Results
- How to Read This Paper
- Introduction
- Related Work
- Experimental Design
- Post-assessment Interview Analysis (Sessions 1–4)
- NLP Analysis
- EEG Analysis
- Topics Analysis
- Discussion
- Limitations and Future Work
- Energy Cost of Interaction
- Conclusions
- Acknowledgments
- Author Contributions
- Conflict of Interest
- References
- Appendix

---

## Introduction

LLMs have fundamentally changed how we work, play, and learn, offering personalized learning, immediate feedback, and democratized education. However, research suggests that LLMs, while reducing immediate cognitive load, may negatively impact deep learning, critical thinking, and autonomy, especially in educational settings. Unlike traditional search engines, LLMs synthesize information into singular responses, potentially discouraging independent judgment. This study focuses on the cognitive impacts of LLMs in the context of essay writing—a complex task engaging multiple mental processes.

**Research Questions:**
1. Do participants write significantly different essays when using LLMs, search engines, or brain-only?
2. How does brain activity differ between these groups?
3. How does LLM usage impact participants' memory?
4. Does LLM usage affect essay ownership?

---

## Related Work

### LLMs and Learning
- LLMs provide contextualized, personalized information, surpassing search engines in adaptability.
- While LLMs facilitate repetition and spaced learning, they can also promote passive consumption, reducing engagement, critical thinking, and long-term memory formation.
- LLMs may introduce inaccuracies or biases and can foster academic laziness or dependence, particularly among students with low self-efficacy.

### Web Search and Learning
- Effective web learning requires domain knowledge and self-regulation.
- The “Search as Learning” framework emphasizes iterative, critical evaluation and integration of multimodal resources.
- The “Google Effect” describes reliance on external memory, lowering information recall but increasing recall of information location.

### Cognitive Load Theory
- Cognitive load is divided into intrinsic, extraneous, and germane loads.
- Both search and LLMs influence cognitive load differently; LLMs reduce overall cognitive load but may compromise deep, schema-building learning (germane load).

### Engagement and Physiological Responses
- High engagement, fostered by effective feedback and personalized learning, leads to better outcomes.
- Web searches activate broader neural networks (decision-making, executive function) than passive reading.
- LLM use may foster immediate but not sustained engagement; deep cognitive engagement can be lower compared to traditional methods.

### Search Engines vs. LLMs
- Search engines are better for broad exploration and fact-checking, promoting active engagement.
- LLMs excel at providing synthesized, contextualized responses, streamlining tasks but possibly reducing critical evaluation.

---

## Experimental Design

### Participants
- 54 participants (aged 18–39) from MIT, Wellesley, Harvard, Tufts, and Northeastern.
- Participants assigned to LLM, Search Engine, or Brain-only groups, balanced by age and gender.
- Each attended three sessions; 18 completed an optional fourth session (crossover).
- Compensation: $100 for three sessions, $50 for the fourth.

### Protocol
1. **Welcome, briefing, background questionnaire**
2. **EEG headset setup** (Neuroelectrics Enobio 32)
3. **Calibration task**: mental math, rest, eye movements
4. **Essay writing task** (20 min, three SAT-style prompts per session)
   - LLM group: Only ChatGPT
   - Search Engine group: Any website except LLMs (Google with “-ai” in queries)
   - Brain-only: No external tools
   - Session 4: Reassignment—LLM group uses brain-only, Brain-only group uses LLM
5. **Post-assessment interview** (8–12 questions)
6. **Debriefing, cleanup, data storage**

### Essay Prompts
- 9 total prompts across sessions (SAT-inspired); in Session 4, participants chose among topics they previously wrote about.

---

## Post-assessment Interview Analysis

### Sessions 1–3
- **Topic Choice:** Most chose prompts resonating with personal experience or interest.
- **Essay Structure:** High adherence to structure across groups; LLM group often used AI for outlining.
- **Quoting Ability:** LLM group had much lower ability to quote or recall their own essays; Brain-only and Search Engine groups performed significantly better.
- **Ownership:** LLM group reported lower ownership, with variability; Brain-only group reported near-universal ownership.
- **Satisfaction:** Search Engine group reported highest satisfaction; LLM and Brain-only groups were also generally satisfied but had more mixed responses.
- **Comments:** LLM group cited ChatGPT as helpful for grammar but “robotic” or irrelevant for creativity; some preferred internet or brain-only approaches.

### Session 4 (Crossover)
- LLM-to-Brain participants had lower quoting ability, recall, and neural connectivity than Brain-only participants.
- Brain-to-LLM participants leveraged LLMs for more information-seeking and prompting.
- Ownership and satisfaction were generally high in both groups, but essay recall and quoting were lower in LLM-to-Brain.
- Participants preferred the Session 4 essay, often citing deeper engagement or detail.

---

## NLP Analysis

### Findings
- **Homogeneity:** LLM and Search Engine groups produced more homogeneous essays within each topic; Brain-only group essays showed higher variability.
- **NERs:** LLM group used the most Named Entities (persons, places, dates); Brain-only used the least.
- **N-grams:** LLM group often reused similar n-grams and structure; Brain-only group demonstrated more original phrasing.
- **Ontology:** LLM and Search Engine groups overlapped significantly in ontology graphs; Brain-only group had distinct ontological structures.
- **AI Judge vs. Human Grading:** Human teachers rated essays lower on uniqueness and content, especially in the LLM group; AI judge tended to rate essays higher and less variably.

---

## EEG Analysis

### Brain-only vs. LLM
- **Alpha band:** Brain-only group showed stronger semantic processing networks (fronto-parietal connectivity).
- **Beta band:** Brain-only group had stronger cognitive and motor engagement.
- **Delta band:** Brain-only group led in executive monitoring and integrative processing.
- **Theta band:** Brain-only group had higher working memory and executive control engagement.

### Brain-only vs. Search Engine
- Brain-only group had greater low-frequency connectivity (delta/theta), supporting internalized cognitive processes, memory retrieval, and integration.
- Search Engine group showed more occipital (visual) and beta band connectivity, reflecting engagement with external information.

### LLM vs. Search Engine
- LLM group exhibited greater internal executive network coherence and planning; Search Engine group engaged more bottom-up, visual-executive integration.

### Session 4 (Crossover)
- LLM-to-Brain participants had lower neural connectivity and engagement; their essays were less original and showed signs of “cognitive debt.”
- Brain-to-LLM participants showed a spike in network engagement when using LLMs after prior unaided writing.

---

## Topics Analysis
- N-gram usage varied by group and session; Brain-only group had more diverse and value-driven language.
- LLM and Search Engine groups often repeated similar phrases and structures.
- EEG data matched linguistic findings: internally-driven, original phrasing aligned with stronger neural coupling.

---

## Discussion

### Key Insights
- **Cognitive Engagement:** LLM use reduces cognitive load and internal engagement, leading to less original, less memorable, and less “owned” essays.
- **Skill Atrophy:** Repeated LLM use impairs memory encoding, creative thinking, and critical evaluation (accumulation of “cognitive debt”).
- **Behavioral Correlates:** Brain-only group had superior quoting ability, memory, and essay ownership; LLM group underperformed in these areas.
- **Learning Outcomes:** LLM use may improve surface performance but hinders deep learning and self-efficacy.
- **Neural Adaptation:** Initial unaided practice followed by AI assistance may be neurocognitively optimal.

### Educational Implications
- Over-reliance on LLMs risks shallow learning and loss of cognitive autonomy. Strategic integration—AI as a support after initial self-driven effort—may balance efficiency and skill development.

---

## Limitations and Future Work
- Limited sample size and demographic (Boston-area students).
- Only ChatGPT was used; generalization to other LLMs is untested.
- EEG spatial resolution limits; future work should include fMRI.
- Did not analyze writing subtasks (e.g., idea generation vs. drafting separately).
- Further studies needed on long-term impacts and on broader, more diverse populations.

---

## Energy Cost of Interaction
- LLM queries consume roughly 10x more energy than search engine queries.
- Potential for increased environmental and consumer costs as LLM usage grows.

---

## Conclusions

LLMs offer efficiency and accessibility but at a cost to deep cognitive engagement, memory, and ownership. Echo chambers and algorithmic curation remain concerns. Human teachers can often recognize LLM-generated text due to its homogeneity and lack of personal nuance. Longitudinal studies are needed to fully understand the lasting impacts of LLMs on learning and cognition.

---

## Acknowledgments

Thanks to Janet Baker for feedback, Lendra Hassman and Luisa Heiss for essay grading, and all other contributors and participants.

## Author Contributions

- NK: Study conception, design, data analysis, manuscript drafting.
- EH: Data analysis, manuscript drafting.
- AVB, YTY, XHL: Data recording.
- JS, IB: Literature drafting, transcription support.
- PM: Study design feedback, manuscript review.

## Conflict of Interest

Dr. Kosmyna holds a Visiting Researcher position at Google (work completed prior to affiliation). No other conflicts declared.

---

## References

(See source for full reference list.)

---

## Appendix

- Interview cluster analyses
- Additional dDTF and EEG result tables
- Ontology and n-gram details
